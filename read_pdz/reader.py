# AUTOGENERATED! DO NOT EDIT! File to edit: ../notebooks/10_parsing-bytes.ipynb.

# %% auto 0
__all__ = ['extract_spectra', 'multiparse', 'prefix', 'file_to_bytes', 'parse', 'read_strings', 'skip_bytes', 'read_table',
           'get_block_at', 'get_blocks']

# %% ../notebooks/10_parsing-bytes.ipynb 21
import struct 
import numpy as np 
import os 
import re
import matplotlib.pyplot as plt
import pandas as pd

# %% ../notebooks/10_parsing-bytes.ipynb 22
def extract_spectra(pdz_file, to_csv=True, verbose=True): 
    '''Directly extract spectral data from `pdz_file`. 
    
    Robust extraction of spectrum counts and energy calibration. Other meta data is ignored. '''

    pdz_bytes = file_to_bytes(pdz_file)
    block_list = get_blocks(pdz_bytes, verbose=False) 
    
    # select type 3 blocks
    b3_list = [b for b in block_list if b['block_type'] == 3] 
    n_spectra = len(b3_list) 

    # parsing spectrum parameters 
    #from first block to compute channel energies (keV) 
    # (assuming that these are similar for all spectra in the pdz file) 
    
    arr = b3_list[0]['bytes'] # only using first block!  
    spectrum_params = multiparse('3i9f7hfhfhfhf8hfhi-S-h', arr, verbose=False)[0]  
    tube_keV = spectrum_params[10] # FYI 
    delta_keV = spectrum_params[23] / 1000
    start_keV = -spectrum_params[25] / 1000 
    n_channels = spectrum_params[35] 
    if n_channels != 2048: 
        print(f'Found unexpected number of channels in pdz metadata: {n_channels}')
        
    stop_keV = start_keV + delta_keV * (n_channels -1)
    x_keV = np.linspace(start_keV, stop_keV, num=n_channels) 

    # initialize array 
    
    spectra_df = pd.DataFrame(index=x_keV)

    # TODO: Test if computed channel energies `x_keV` are reasonable, 
    # Parsing of spectrum parameters might fail 
    # if Bruker messes with file format.   
    # otherwise fall back on 0-40 keV range  

    spectrum_list = [] 

    for i, b3 in enumerate(b3_list):  
        arr = b3['bytes'] 
        counts = np.array(parse(f'{n_channels}i', arr[-4*n_channels:], verbose=False)[0])  

        spectra_df[f'spectrum #{i+1}'] = counts

    if to_csv == True: 
        spectra_df.to_csv(f'{pdz_file}.spectral_data.csv', float_format='%10.5f')

    return spectra_df
           

def multiparse(xformat, arr, verbose=True): 
    '''Parse segments in extendend format string `xformat` e.g. '<i5f-2S-T-3S-S-f' '''

    
    parts = re.split('-', xformat) 

    result_list = []
    for p in parts: 
        if 'S' in p:
            result, arr = read_strings(p, arr, verbose=False) 
        elif p == 'T': 
            result, arr = read_table(p, arr, verbose=False) 
        elif 'X' in p: 
            result, arr = skip_bytes(p, arr, verbose=False) 
        else: 
            result, arr = parse(p, arr, verbose=False) 
            
        result_list.extend(result)   

    if verbose: 
        print(result_list)

    return result_list, arr   

def prefix(format): 
    '''Prefix little endian byte order (<) to struct type format string if missing. '''

    if not format.startswith('<'): 
        format = f'<{format}'
    
    return format    

def file_to_bytes(pdz_file): 
    '''Read all bytes from filepath `pdz_file` into a byte array. 
    
    Returns: `pdz_arr` (numpy array of bytes)
    '''

    with open(pdz_file, 'rb') as fh: 
        blob = fh.read() 
        
    pdz_arr = np.array([v[0] for v in struct.iter_unpack('c', blob)])
    #pdz_arr = bytearray(blob)

    return pdz_arr 
    

def parse(format, arr, verbose=True): 
    '''Parse first bytes from bytes array `arr` into human readable text according to `format` string. 
    
    See struct library for format string specification. For example, '<ff' would result 
    the first 8 bytes to be converted into two Little-Endian floats. 
    
    Returns: `parsed` list and remaining bytes array of `tail_arr` unprocessed `values`.'''

    format = prefix(format) 
    size = struct.calcsize(format)
    buffer = arr[0:size]
    tail_arr = arr[size:]

    parsed = list(struct.unpack(format, buffer)) 

    if verbose: 
        print(parsed)
    
    return parsed, tail_arr

def read_strings(xformat, arr, verbose=True): 
    '''Parse `n` variable length character strings preceded by a length integer. 
     
    '''
    # get multiplier  
    if xformat == 'S': 
        n = 1
    else: 
        n = int(re.sub('(^\d+)S', '\g<1>', xformat))

    # parse strings 
    string_list = [] 
    while n > 0: 
        [length], arr = parse('<i', arr, verbose=False) # read length 
        n_bytes = 2 * length 

        # do some testing 
        assert (n_bytes > 1) and (type(n_bytes) is int), f'{n_bytes} is invalid string length' 
        
        char_list, arr = parse(f'<{n_bytes}c', arr, verbose=False) 
        string = b''.join(char_list).decode(encoding='utf-16') 
        string_list.append(string) 
        n = n -1 
        
    if verbose: 
        print(string_list) 

    return string_list, arr


def skip_bytes(xformat, arr, verbose=True): 
    '''Skip `n_bytes`'''

    # get multiplier  
    if xformat == 'X': 
        n_bytes = 1
    else: 
        n_bytes = int(re.sub('(^\d+)X', '\g<1>', xformat))

    skipped = [b''.join(arr[0:n_bytes])] 

    arr = arr[n_bytes:] 

    if verbose: 
        print(skipped)

    return skipped, arr 
    

def read_table(xformat, arr, verbose=True): 
    '''Extract numbered table'''

    assert xformat == 'T', 'Incorrect format string'

    [table_length], arr = parse('<i', arr, verbose=False) 

    table = []
    for i in range(table_length): 
        [num], arr = parse('<h', arr, verbose=False)  
        [string], arr = read_strings('S', arr, verbose=False)
        table.append([f'#{num}', string]) 
        
    if verbose: 
        print(table)

    return [table], arr
    

def get_block_at(pdz_arr, start): 
    '''Read first data block from bytes array `pdz_arr` from index position `start`. 

    Assumes that first 4 bytes are (block type and size)
    
    Returns: `block_dict`, `block` 
    '''

    file_size = len(pdz_arr)
    
    [block_type, block_size], arr = parse('<hi', pdz_arr[start:], verbose=False)
    
    block_type = struct.unpack('<h', pdz_arr[start:start+2])[0] 
    size = struct.unpack('<i', pdz_arr[start+2:start+6])[0] 
    stop = start + size + 6 # four bytes extra due to `dtype` and `size` shorts plus two empty pad bytes? 

    # read block bytes
    arr = pdz_arr[start+6:stop] 
    
    block_dict = {'block_type': block_type, 'size': size, 'start': start, 'stop': stop, 
                  'file_size': file_size, 'bytes': arr}

    return block_dict


def get_blocks(pdz_bytes, verbose=True): 
    '''Parse `pdz_byte_array` into consequtive blocks. ''' 

    if verbose: 
        print('Detecting block sequence...')
    
    start = 0 
    total_size = len(pdz_bytes) 

    block_list = [] 
    while start < total_size: 
        block_dict = get_block_at(pdz_bytes, start)
        start = block_dict['stop']
        block_list.append(block_dict)

    else:
        if start == total_size: 
            if verbose: 
                print('Ok!')
        else: 
            print('Error while reading last block! ')
            print(f'Stop index: {start} does not match total file size: {total_size}')
        
    return block_list
       
